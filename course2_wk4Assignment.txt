1. 
Which of the following is NOT a valid measure of overfitting?


Sum of parameters (w1+w2+...+wn) c 
Sum of squares of parameters (w_1^2 + w_2^2 + … +w_n^2w )
Range of parameters, i.e., difference between maximum and minimum parameters . 
Sum of absolute values of parameters (|w_1| + |w_2| + … + |w_n|)

2. 
In ridge regression, choosing a large penalty strength lambdaλ tends to lead to a model with (choose all that apply):


High bias c 
Low bias
High variance
Low variance c 

4.In ridge regression using unnormalized features, if you double the value of a given feature (i.e., a specific column of the feature matrix), what happens to the estimated coefficients for every other feature? They:


Double
Half .
Stay the same .
Impossible to tell from the information provided c

5.If we only have a small number of observations, K-fold cross validation provides a better estimate of the generalization error than the validation set method.
True. c 
False

6. 10-fold cross validation is more computationally intensive than leave-one-out (LOO) cross validation.

True
False c 


7.Assume you have a training dataset consisting of NN observations and DD features. You use the closed-form solution to fit a multiple linear regression model using ridge regression. To choose the penalty strength \lambdaλ, you run leave-one-out (LOO) cross validation searching over LL values of \lambdaλ. Let Cost(N,D) be the computational cost of running ridge regression with NN data points and DD features. Assume the prediction cost is negligible compared to the computational cost of training the model. Which of the following represents the computational cost of your LOO cross validation procedure?


LN⋅Cost(N,D)
LN⋅Cost(N−1,D) c
LD⋅Cost(N−1,D)
LD⋅Cost(N,D)
L⋅Cost(N−1,D).  
L⋅Cost(N,D)

For each lambda, if you using LOO, you need to compute N (your observations) times where each time you need to trained a fitted model; if you K-fold CV, you need to compute K times where each time you need to trained a fitted model.

8.Assume you have a training dataset consisting of 1 million observations. Suppose running the closed-form solution to fit a multiple linear regression model using ridge regression on this data takes 1 second. Suppose you want to choose the penalty strength lambda λ by searching over 100 possible values. How long will it take to run leave-one-out (LOO) cross-validation for this selection task?


About 3 hours .
About 3 days .
About 3 years c
About 3 decades

L = 100
N = 1,000,000
Cost(N-1,D) = 1 second
Time = L∗N∗Cost(N−1,D) = 100,000,000 seconds = 3 years

9.Assume you have a training dataset consisting of 1 million observations. Suppose running the closed-form solution to fit a multiple linear regression model using ridge regression on this data takes 1 second. Suppose you want to choose the penalty strength \lambdaλ by searching over 100 possible values. If you only want to spend about 1 hour to select \lambdaλ, what value of k should you use for k-fold cross-validation?


k=6
k=36 c 
k=600
k=3600

as you only want to spend about 1 hour to select \lambdaλ 
and want to choose the penalty strength \lambdaλ by searching over 100 possible values
3600sec => 100 values
so k =3600/100


