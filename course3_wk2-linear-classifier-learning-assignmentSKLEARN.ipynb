{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset into a data frame named products. One column of this dataset is sentiment, corresponding to the class label with +1 indicating a review with positive sentiment and -1 for negative sentiment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products =pd.read_csv('amazon_baby_subset.csv')\n",
    "type(products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumbuddy To Love's Binky Fairy Puppet and Adorable Book</td>\n",
       "      <td>All of my kids have cried non-stop when I tried to ween them off their pacifier, until I found Thumbuddy To Love's Binky Fairy Puppet.  It is an easy way to work with your kids to allow them to understand where their pacifier is going and help them part from it.This is a must buy book, and a great gift for expecting parents!!  You will save them soo many headaches.Thanks for this book!  You all rock!!</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>We wanted to get something to keep track of our child's milestones and this is a cute option. There aren't many other choices out there and this does exactly what we wanted.</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                name  \\\n",
       "0  Stop Pacifier Sucking without tears with Thumbuddy To Love's Binky Fairy Puppet and Adorable Book   \n",
       "1  Nature's Lullabies Second Year Sticker Calendar                                                     \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                 review  \\\n",
       "0  All of my kids have cried non-stop when I tried to ween them off their pacifier, until I found Thumbuddy To Love's Binky Fairy Puppet.  It is an easy way to work with your kids to allow them to understand where their pacifier is going and help them part from it.This is a must buy book, and a great gift for expecting parents!!  You will save them soo many headaches.Thanks for this book!  You all rock!!   \n",
       "1  We wanted to get something to keep track of our child's milestones and this is a cute option. There aren't many other choices out there and this does exactly what we wanted.                                                                                                                                                                                                                                          \n",
       "\n",
       "   rating  sentiment  \n",
       "0  5       1          \n",
       "1  5       1          "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1, ..., -1, -1, -1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products['sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Stop Pacifier Sucking without tears with Thumbuddy To Love's Binky Fairy Puppet and Adorable Book\n",
       "1    Nature's Lullabies Second Year Sticker Calendar                                                  \n",
       "2    Nature's Lullabies Second Year Sticker Calendar                                                  \n",
       "3    Lamaze Peekaboo, I Love You                                                                      \n",
       "4    SoftPlay Peek-A-Boo Where's Elmo A Children's Book                                               \n",
       "5    Our Baby Girl Memory Book                                                                        \n",
       "6    Hunnt&reg; Falling Flowers and Birds Kids Nursery Home Decor Vinyl Mural Art Wall Paper Stickers \n",
       "7    Blessed By Pope Benedict XVI Divine Mercy Full Color Medal                                       \n",
       "8    Cloth Diaper Pins Stainless Steel Traditional Safety Pin (Black)                                 \n",
       "9    Cloth Diaper Pins Stainless Steel Traditional Safety Pin (Black)                                 \n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head(10)['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of positive reviews = 26579\n",
      "# of negative reviews = 26493\n"
     ]
    }
   ],
   "source": [
    "print '# of positive reviews =', len(products[products['sentiment']==1])\n",
    "print '# of negative reviews =', len(products[products['sentiment']==-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply text cleaning on the review data\n",
    "\n",
    "In this section, we will perform some simple feature cleaning using data frames. The last assignment used all words in building bag-of-words features, but here we limit ourselves to 193 words (for simplicity). We compiled a list of 193 most frequent words into the JSON file named important_words.json. \n",
    "\n",
    "Load the words into a list important_words.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n",
      "[u'baby', u'one', u'great', u'love', u'use']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('important_words.json','r') as f :\n",
    "    important_words = json.load(f)\n",
    "print type(important_words)\n",
    "print important_words[0:5]\n",
    "\n",
    "#converting it to list altough it gives list above but with u''\n",
    "important_words=[str(s) for s in important_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['baby', 'one', 'great', 'love', 'use', 'would', 'like', 'easy', 'little', 'seat', 'old', 'well', 'get', 'also', 'really', 'son', 'time', 'bought', 'product', 'good', 'daughter', 'much', 'loves', 'stroller', 'put', 'months', 'car', 'still', 'back', 'used', 'recommend', 'first', 'even', 'perfect', 'nice', 'bag', 'two', 'using', 'got', 'fit', 'around', 'diaper', 'enough', 'month', 'price', 'go', 'could', 'soft', 'since', 'buy', 'room', 'works', 'made', 'child', 'keep', 'size', 'small', 'need', 'year', 'big', 'make', 'take', 'easily', 'think', 'crib', 'clean', 'way', 'quality', 'thing', 'better', 'without', 'set', 'new', 'every', 'cute', 'best', 'bottles', 'work', 'purchased', 'right', 'lot', 'side', 'happy', 'comfortable', 'toy', 'able', 'kids', 'bit', 'night', 'long', 'fits', 'see', 'us', 'another', 'play', 'day', 'money', 'monitor', 'tried', 'thought', 'never', 'item', 'hard', 'plastic', 'however', 'disappointed', 'reviews', 'something', 'going', 'pump', 'bottle', 'cup', 'waste', 'return', 'amazon', 'different', 'top', 'want', 'problem', 'know', 'water', 'try', 'received', 'sure', 'times', 'chair', 'find', 'hold', 'gate', 'open', 'bottom', 'away', 'actually', 'cheap', 'worked', 'getting', 'ordered', 'came', 'milk', 'bad', 'part', 'worth', 'found', 'cover', 'many', 'design', 'looking', 'weeks', 'say', 'wanted', 'look', 'place', 'purchase', 'looks', 'second', 'piece', 'box', 'pretty', 'trying', 'difficult', 'together', 'though', 'give', 'started', 'anything', 'last', 'company', 'come', 'returned', 'maybe', 'took', 'broke', 'makes', 'stay', 'instead', 'idea', 'head', 'said', 'less', 'went', 'working', 'high', 'unit', 'seems', 'picture', 'completely', 'wish', 'buying', 'babies', 'won', 'tub', 'almost', 'either']\n"
     ]
    }
   ],
   "source": [
    "print important_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#4. Let us perform 2 simple data transformations:\n",
    "\n",
    "Remove punctuation\n",
    "Compute word counts (only for important_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with the first item as follows:\n",
    "\n",
    "    \n",
    "If your tool supports it, fill n/a values in the review column with empty strings. The n/a values indicate empty reviews. For instance, Pandas's the fillna() method lets you replace all N/A's in the review columns as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name         90 \n",
      "review       241\n",
      "rating       0  \n",
      "sentiment    0  \n",
      "dtype: int64\n",
      "                                            name review  rating  sentiment\n",
      "455   DEX Products Pregnancy Pillow PP-01         NaN    5       1        \n",
      "1534  Fisher-Price Booster Seat, Blue/Green/Gray  NaN    5       1        \n"
     ]
    }
   ],
   "source": [
    "# to find number of na values in products for each col\n",
    "print products.isnull().sum()\n",
    "\n",
    "print products[products['review'].isnull()].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products =products.fillna({'review':''})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name         90\n",
      "review       0 \n",
      "rating       0 \n",
      "sentiment    0 \n",
      "dtype: int64\n",
      "Empty DataFrame\n",
      "Columns: [name, review, rating, sentiment]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# here you can see all the N/A review fields have been filled with spaces \n",
    "print products.isnull().sum()\n",
    "print products[products['review'].isnull()].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function remove_punctuation that takes a line of text and removes all punctuation from that text. \n",
    "\n",
    "The function should be analogous to the following Python code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    import string\n",
    "    return text.translate(None,string.punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the remove_punctuation function on every element of the review column and assign the result to the new column review_clean.\n",
    "\n",
    "**Note**. Many data frame packages support apply operation for this type of task. Consult appropriate manuals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "products['review_clean']=products['review'].map(lambda x: remove_punctuation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53072\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumbuddy To Love's Binky Fairy Puppet and Adorable Book</td>\n",
       "      <td>All of my kids have cried non-stop when I tried to ween them off their pacifier, until I found Thumbuddy To Love's Binky Fairy Puppet.  It is an easy way to work with your kids to allow them to understand where their pacifier is going and help them part from it.This is a must buy book, and a great gift for expecting parents!!  You will save them soo many headaches.Thanks for this book!  You all rock!!</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>All of my kids have cried nonstop when I tried to ween them off their pacifier until I found Thumbuddy To Loves Binky Fairy Puppet  It is an easy way to work with your kids to allow them to understand where their pacifier is going and help them part from itThis is a must buy book and a great gift for expecting parents  You will save them soo many headachesThanks for this book  You all rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nature's Lullabies Second Year Sticker Calendar</td>\n",
       "      <td>We wanted to get something to keep track of our child's milestones and this is a cute option. There aren't many other choices out there and this does exactly what we wanted.</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>We wanted to get something to keep track of our childs milestones and this is a cute option There arent many other choices out there and this does exactly what we wanted</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                name  \\\n",
       "0  Stop Pacifier Sucking without tears with Thumbuddy To Love's Binky Fairy Puppet and Adorable Book   \n",
       "1  Nature's Lullabies Second Year Sticker Calendar                                                     \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                 review  \\\n",
       "0  All of my kids have cried non-stop when I tried to ween them off their pacifier, until I found Thumbuddy To Love's Binky Fairy Puppet.  It is an easy way to work with your kids to allow them to understand where their pacifier is going and help them part from it.This is a must buy book, and a great gift for expecting parents!!  You will save them soo many headaches.Thanks for this book!  You all rock!!   \n",
       "1  We wanted to get something to keep track of our child's milestones and this is a cute option. There aren't many other choices out there and this does exactly what we wanted.                                                                                                                                                                                                                                          \n",
       "\n",
       "   rating  sentiment  \\\n",
       "0  5       1           \n",
       "1  5       1           \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                               review_clean  \n",
       "0  All of my kids have cried nonstop when I tried to ween them off their pacifier until I found Thumbuddy To Loves Binky Fairy Puppet  It is an easy way to work with your kids to allow them to understand where their pacifier is going and help them part from itThis is a must buy book and a great gift for expecting parents  You will save them soo many headachesThanks for this book  You all rock  \n",
       "1  We wanted to get something to keep track of our childs milestones and this is a cute option There arent many other choices out there and this does exactly what we wanted                                                                                                                                                                                                                                 "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print len(products['review_clean'])\n",
    "products.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*5*. Now we proceed with the second item. For each word in **important_words**, \n",
    "we compute a count for the number of times the word occurs in the review. \n",
    "\n",
    "We will store this count in a separate column (one for each word). The result of this feature processing is a single column for each word in important_words which keeps a count of the number of times the respective word occurs in the review text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for word in important_words:\n",
    "    products[word] = products['review_clean'].map(lambda x:x.split().count(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>baby</th>\n",
       "      <th>one</th>\n",
       "      <th>great</th>\n",
       "      <th>love</th>\n",
       "      <th>use</th>\n",
       "      <th>...</th>\n",
       "      <th>seems</th>\n",
       "      <th>picture</th>\n",
       "      <th>completely</th>\n",
       "      <th>wish</th>\n",
       "      <th>buying</th>\n",
       "      <th>babies</th>\n",
       "      <th>won</th>\n",
       "      <th>tub</th>\n",
       "      <th>almost</th>\n",
       "      <th>either</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumbuddy To Love's Binky Fairy Puppet and Adorable Book</td>\n",
       "      <td>All of my kids have cried non-stop when I tried to ween them off their pacifier, until I found Thumbuddy To Love's Binky Fairy Puppet.  It is an easy way to work with your kids to allow them to understand where their pacifier is going and help them part from it.This is a must buy book, and a great gift for expecting parents!!  You will save them soo many headaches.Thanks for this book!  You all rock!!</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>All of my kids have cried nonstop when I tried to ween them off their pacifier until I found Thumbuddy To Loves Binky Fairy Puppet  It is an easy way to work with your kids to allow them to understand where their pacifier is going and help them part from itThis is a must buy book and a great gift for expecting parents  You will save them soo many headachesThanks for this book  You all rock</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                name  \\\n",
       "0  Stop Pacifier Sucking without tears with Thumbuddy To Love's Binky Fairy Puppet and Adorable Book   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                 review  \\\n",
       "0  All of my kids have cried non-stop when I tried to ween them off their pacifier, until I found Thumbuddy To Love's Binky Fairy Puppet.  It is an easy way to work with your kids to allow them to understand where their pacifier is going and help them part from it.This is a must buy book, and a great gift for expecting parents!!  You will save them soo many headaches.Thanks for this book!  You all rock!!   \n",
       "\n",
       "   rating  sentiment  \\\n",
       "0  5       1           \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                               review_clean  \\\n",
       "0  All of my kids have cried nonstop when I tried to ween them off their pacifier until I found Thumbuddy To Loves Binky Fairy Puppet  It is an easy way to work with your kids to allow them to understand where their pacifier is going and help them part from itThis is a must buy book and a great gift for expecting parents  You will save them soo many headachesThanks for this book  You all rock   \n",
       "\n",
       "   baby  one  great  love  use   ...    seems  picture  completely  wish  \\\n",
       "0  0     0    1      0     0     ...    0      0        0           0      \n",
       "\n",
       "   buying  babies  won  tub  almost  either  \n",
       "0  0       0       0    0    0       0       \n",
       "\n",
       "[1 rows x 198 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*6.* After #4 and #5, the data frame products should contain one column for each of the 193 important_words. As an example, the column perfect contains a count of the number of times the word perfect occurs in each of the reviews.\n",
    "\n",
    "*7.* Now, write some code to compute the number of product reviews that contain the word perfect.\n",
    "\n",
    "\n",
    "**Hint**:\n",
    "\n",
    "First create a column called contains_perfect which is set to 1 if the count of the word perfect (stored in column perfect is >= 1.\n",
    "\n",
    "Sum the number of 1s in the column contains_perfect.\n",
    "\n",
    "\n",
    "**Quiz Question.** How many reviews contain the word perfect?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "products['contains_perfect'] = products['perfect'].map(lambda x:1 if x>=1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2955"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Quiz Question. How many reviews contain the word perfect?\n",
    "products['contains_perfect'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert data frame to multi-dimensional array**\n",
    "\n",
    "*8.* It is now time to convert our data frame to a multi-dimensional array. Look for a package that provides a highly optimized matrix operations. In the case of Python, NumPy is a good choice.\n",
    "\n",
    "\n",
    "Write a function that extracts columns from a data frame and converts them into a multi-dimensional array. \n",
    "\n",
    "We plan to use them throughout the course, so make sure to get this function right.\n",
    "\n",
    "The function should accept three parameters:\n",
    "\n",
    "dataframe: a data frame to be converted\n",
    "\n",
    "features: a list of string, containing the names of the columns that are used as features.\n",
    "\n",
    "label: a string, containing the name of the single column that is used as class labels.\n",
    "\n",
    "The function should return two values:\n",
    "\n",
    "one 2D array for features\n",
    "one 1D array for class labels\n",
    "The function should do the following:\n",
    "\n",
    "Prepend a new column constant to dataframe and fill it with 1's. This column takes account of the intercept term. \n",
    "\n",
    "Make sure that the constant column appears first in the data frame.\n",
    "\n",
    "Prepend a string 'constant' to the list features. Make sure the string 'constant' appears first in the list.\n",
    "\n",
    "Extract columns in dataframe whose names appear in the list features.\n",
    "\n",
    "Convert the extracted columns into a 2D array using a function in the data frame library. If you are using Pandas, you would use as_matrix() function.\n",
    "\n",
    "Extract the single column in dataframe whose name corresponds to the string label.\n",
    "Convert the column into a 1D array.\n",
    "Return the 2D array and the 1D array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_numpy_data(data_sframe,features,label):\n",
    "    # add a constant column to an SFrame \n",
    "    data_sframe['intercept'] =1 \n",
    "    features = ['intercept'] + features \n",
    "    # select the columns of data_SFrame given by the ‘features’ list into the SFrame ‘features_sframe’\n",
    "    features_sframe =data_sframe[features]\n",
    "    # this will convert the features_sframe into a numpy matrix  \n",
    "    feature_matrix = features_sframe.as_matrix(columns=None)\n",
    "    \n",
    "    # assign the column of data_sframe associated with the target to the variable ‘output_sarray’\n",
    "    label_sarray=data_sframe[label]\n",
    "    # this will convert the SArray into a numpy array\n",
    "    label_array = label_sarray.as_matrix(columns=None)\n",
    "    return(feature_matrix,label_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*9.* Using the function written in #8, extract two arrays feature_matrix and sentiment. \n",
    "\n",
    "The 2D array feature_matrix would contain the content of the columns given by the list important_words. \n",
    "The 1D array sentiment would contain the content of the column sentiment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Warning: This may take a few minutes...\n",
    "\n",
    "feature_matrix, sentiment =get_numpy_data(products,important_words,'sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53072, 194)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 1, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 1, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question**: How many features are there in the feature_matrix?\n",
    "\n",
    "**Quiz Question**: Assuming that the intercept is present, how does the number of features in feature_matrix relate to the number of features in the logistic regression model?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "194"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print type(feature_matrix)\n",
    "\n",
    "#How many features are there in the feature_matrix?\n",
    "# it is the number of columns in feature matrix\n",
    "feature_matrix.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Assuming that the intercept is present, how does the number of features in feature_matrix relate to the \n",
    "# number of features in the logistic regression model?\n",
    "\n",
    "# doubt ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us see what the **sentiment** column looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1, ..., -1, -1, -1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating conditional probability with link function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall from lecture that the link function is given by:\n",
    "$$\n",
    "P(y_i = +1 | \\mathbf{x}_i,\\mathbf{w}) = \\frac{1}{1 + \\exp(-\\mathbf{w}^T h(\\mathbf{x}_i))},\n",
    "$$\n",
    "\n",
    "where the feature vector $h(\\mathbf{x}_i)$ represents the word counts of **important_words** in the review  $\\mathbf{x}_i$. Complete the following function that implements the link function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "produces probablistic estimate for P(y_i = +1 | x_i, w).\n",
    "estimate ranges between 0 and 1.\n",
    "'''\n",
    "def predict_probability(feature_matrix, coefficients):\n",
    "    # Take dot product of feature_matrix and coefficients  \n",
    "    # YOUR CODE HERE\n",
    "    #score = np.dot(feature_matrix,coefficients)\n",
    "    score = np.matmul(feature_matrix,coefficients)\n",
    "    \n",
    "    # Compute P(y_i = +1 | x_i, w) using the link function\n",
    "    # YOUR CODE HERE\n",
    "    predictions =  1/(1+np.exp(-1*score))\n",
    "    \n",
    "    # return predictions\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,) (2, 3)\n",
      "[ 4. -1.]\n",
      "[ 4. -1.]\n"
     ]
    }
   ],
   "source": [
    "dummy_feature_matrix = np.array([[1.,2.,3.], [1.,-1.,-1]])\n",
    "dummy_coefficients = np.array([1., 3., -1.])\n",
    "print dummy_coefficients.shape,dummy_feature_matrix.shape\n",
    "print np.matmul(dummy_feature_matrix, dummy_coefficients) # (2 cross 3) (3 cross 1)\n",
    "print np.dot(dummy_feature_matrix,dummy_coefficients)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint**\n",
    "\n",
    "Just to make sure you are on the right track, we have provided a few examples. If your `predict_probability` function is implemented correctly, then the outputs will match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following outputs must match \n",
      "------------------------------------------------\n",
      "correct_predictions           = [ 0.98201379  0.26894142]\n",
      "output of predict_probability = [ 0.98201379  0.26894142]\n"
     ]
    }
   ],
   "source": [
    "dummy_feature_matrix = np.array([[1.,2.,3.], [1.,-1.,-1]])\n",
    "dummy_coefficients = np.array([1., 3., -1.])\n",
    "\n",
    "correct_scores      = np.array( [ 1.*1. + 2.*3. + 3.*(-1.),          1.*1. + (-1.)*3. + (-1.)*(-1.) ] )\n",
    "correct_predictions = np.array( [ 1./(1+np.exp(-correct_scores[0])), 1./(1+np.exp(-correct_scores[1])) ] )\n",
    "\n",
    "print 'The following outputs must match '\n",
    "print '------------------------------------------------'\n",
    "print 'correct_predictions           =', correct_predictions\n",
    "print 'output of predict_probability =', predict_probability(dummy_feature_matrix, dummy_coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Compute derivative of log likelihood with respect to a single coefficient\n",
    "\n",
    "Recall from lecture:\n",
    "$$\n",
    "\\frac{\\partial\\ell}{\\partial w_j} = \\sum_{i=1}^N h_j(\\mathbf{x}_i)\\left(\\mathbf{1}[y_i = +1] - P(y_i = +1 | \\mathbf{x}_i, \\mathbf{w})\\right)\n",
    "$$\n",
    "\n",
    "We will now write a function that computes the derivative of log likelihood with respect to a single coefficient $w_j$. The function accepts two arguments:\n",
    "* `errors` vector containing $\\mathbf{1}[y_i = +1] - P(y_i = +1 | \\mathbf{x}_i, \\mathbf{w})$ for all $i$.\n",
    "* `feature` vector containing $h_j(\\mathbf{x}_i)$  for all $i$. \n",
    "\n",
    "Complete the following code block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_derivative(errors, feature):     \n",
    "    # Compute the dot product of errors and feature\n",
    "    derivative = np.dot(errors,feature)\n",
    "    \n",
    "    # Return the derivative\n",
    "    return derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the main lecture, our focus was on the likelihood.  In the advanced optional video, however, we introduced a transformation of this likelihood---called the log likelihood---that simplifies the derivation of the gradient and is more numerically stable.  Due to its numerical stability, we will use the log likelihood instead of the likelihood to assess the algorithm.\n",
    "\n",
    "The log likelihood is computed using the following formula (see the advanced optional video if you are curious about the derivation of this equation):\n",
    "\n",
    "$$\\ell\\ell(\\mathbf{w}) = \\sum_{i=1}^N \\Big( (\\mathbf{1}[y_i = +1] - 1)\\mathbf{w}^T h(\\mathbf{x}_i) - \\ln\\left(1 + \\exp(-\\mathbf{w}^T h(\\mathbf{x}_i))\\right) \\Big) $$\n",
    "\n",
    "We provide a function to compute the log likelihood for the entire dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_log_likelihood(feature_matrix,sentiment,coefficients):\n",
    "    indicator = (sentiment==+1)\n",
    "    scores = np.dot(feature_matrix,coefficients)\n",
    "    lp = np.sum((indicator-1)*scores - np.log(1+np.exp(-1*scores)))\n",
    "    return lp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint**\n",
    "\n",
    "Just to make sure we are on the same page, run the following code block and check that the outputs match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following outputs must match \n",
      "------------------------------------------------\n",
      "correct_log_likelihood           = -5.33141161544\n",
      "output of compute_log_likelihood = -5.33141161544\n"
     ]
    }
   ],
   "source": [
    "dummy_feature_matrix = np.array([[1.,2.,3.], [1.,-1.,-1]])\n",
    "dummy_coefficients = np.array([1., 3., -1.])\n",
    "dummy_sentiment = np.array([-1, 1])\n",
    "\n",
    "correct_indicators  = np.array( [ -1==+1, 1==+1 ] )\n",
    "correct_scores      = np.array( [ 1.*1. + 2.*3. + 3.*(-1.), 1.*1. + (-1.)*3. + (-1.)*(-1.) ] )\n",
    "correct_first_term  = np.array( [ (correct_indicators[0]-1)*correct_scores[0],  (correct_indicators[1]-1)*correct_scores[1] ] )\n",
    "correct_second_term = np.array( [ np.log(1. + np.exp(-correct_scores[0])), np.log(1. + np.exp(-correct_scores[1])) ] )\n",
    "\n",
    "correct_ll          =      sum( [ correct_first_term[0]-correct_second_term[0], correct_first_term[1]-correct_second_term[1] ] ) \n",
    "\n",
    "print 'The following outputs must match '\n",
    "print '------------------------------------------------'\n",
    "print 'correct_log_likelihood           =', correct_ll\n",
    "print 'output of compute_log_likelihood =', compute_log_likelihood(dummy_feature_matrix, dummy_sentiment, dummy_coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Taking gradient steps**\n",
    "Now we are ready to implement our own logistic regression. All we have to do is to write a gradient ascent function that takes gradient steps towards the optimum.\n",
    "\n",
    "Complete the following function to solve the logistic regression model using gradient ascent:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function logistic_regression to fit a logistic regression model using **gradient ascent.**\n",
    "\n",
    "The function accepts the following parameters:\n",
    "\n",
    "feature_matrix: 2D array of features\n",
    "\n",
    "sentiment: 1D array of class labels\n",
    "\n",
    "initial_coefficients: 1D array containing initial values of coefficients\n",
    "\n",
    "step_size: a parameter controlling the size of the gradient steps\n",
    "\n",
    "max_iter: number of iterations to run gradient ascent\n",
    "\n",
    "The function returns the last set of coefficients after performing gradient ascent.\n",
    "\n",
    "The function carries out the following steps:\n",
    "\n",
    "Initialize vector coefficients to initial_coefficients.\n",
    "\n",
    "Predict the class probability P(y_i = +1|x_i,w)  using your predict_probability function and save it to variable predictions.\n",
    "\n",
    "Save it to variable indicator.\n",
    "\n",
    "Compute the errors as difference between indicator and predictions. \n",
    "\n",
    "Save the errors to variable errors.\n",
    "\n",
    "For each j-th coefficient, compute the per-coefficient derivative by calling feature_derivative with the j-th column of feature_matrix. \n",
    "\n",
    "Then increment the j-th coefficient by (step_size*derivative).\n",
    "\n",
    "Once in a while, insert code to print out the log likelihood.\n",
    "\n",
    "Repeat steps 2-6 for max_iter times.\n",
    "\n",
    "At the end of day, your code should be analogous to the following Python function (with blanks filled in):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "def logistic_regression(feature_matrix,sentiment,initial_coefficients,step_size,max_iter):\n",
    "    coefficients= np.array(initial_coefficients) #make sure its a numpy array \n",
    "    for itr in xrange(max_iter):\n",
    "        # Predict P(y_i = +1|x_1,w) using your predict_probability() function\n",
    "        # YOUR CODE HERE\n",
    "        predictions = predict_probability(feature_matrix, coefficients)\n",
    "        # Compute indicator value for (y_i = +1)\n",
    "        indicator = (sentiment==+1)\n",
    "        # Compute the errors as indicator - predictions\n",
    "        errors = indicator - predictions\n",
    "        for j in xrange(len(coefficients)): # loop over each coefficient \n",
    "            # Recall that feature_matrix[:,j] is the feature column associated with coefficients[j]\n",
    "            # compute the derivative for coefficients[j]. Save it in a variable called derivative\n",
    "            derivative=feature_derivative(errors, feature_matrix[:,j])\n",
    "            \n",
    "            # add the step size times the derivative to the current coefficient\n",
    "            coefficients[j] = coefficients[j] + step_size*derivative\n",
    "            \n",
    "        # Checking whether log likelihood is increasing\n",
    "        if itr <= 15 or (itr <= 100 and itr % 10 == 0) or (itr <= 1000 and itr % 100 == 0) \\\n",
    "        or (itr <= 10000 and itr % 1000 == 0) or itr % 10000 == 0:\n",
    "            lp = compute_log_likelihood(feature_matrix,sentiment,coefficients)\n",
    "            print 'iteration %*d: log likelihood of observed labels = %.8f' % \\\n",
    "                (int(np.ceil(np.log10(max_iter))), itr, lp)\n",
    "    return coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us run the logistic regression solver with the parameters below:\n",
    "\n",
    "feature_matrix = feature_matrix extracted in #9\n",
    "\n",
    "sentiment = sentiment extracted in #9\n",
    "\n",
    "initial_coefficients = a 194-dimensional vector filled with zeros\n",
    "\n",
    "step_size = 1e-7\n",
    "\n",
    "max_iter = 301\n",
    "\n",
    "Save the returned coefficients to variable coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53072, 194) (194,)\n",
      "iteration   0: log likelihood of observed labels = -36780.91768478\n",
      "iteration   1: log likelihood of observed labels = -36775.13434712\n",
      "iteration   2: log likelihood of observed labels = -36769.35713564\n",
      "iteration   3: log likelihood of observed labels = -36763.58603240\n",
      "iteration   4: log likelihood of observed labels = -36757.82101962\n",
      "iteration   5: log likelihood of observed labels = -36752.06207964\n",
      "iteration   6: log likelihood of observed labels = -36746.30919497\n",
      "iteration   7: log likelihood of observed labels = -36740.56234821\n",
      "iteration   8: log likelihood of observed labels = -36734.82152213\n",
      "iteration   9: log likelihood of observed labels = -36729.08669961\n",
      "iteration  10: log likelihood of observed labels = -36723.35786366\n",
      "iteration  11: log likelihood of observed labels = -36717.63499744\n",
      "iteration  12: log likelihood of observed labels = -36711.91808422\n",
      "iteration  13: log likelihood of observed labels = -36706.20710739\n",
      "iteration  14: log likelihood of observed labels = -36700.50205049\n",
      "iteration  15: log likelihood of observed labels = -36694.80289716\n",
      "iteration  20: log likelihood of observed labels = -36666.39512033\n",
      "iteration  30: log likelihood of observed labels = -36610.01327118\n",
      "iteration  40: log likelihood of observed labels = -36554.19728365\n",
      "iteration  50: log likelihood of observed labels = -36498.93316099\n",
      "iteration  60: log likelihood of observed labels = -36444.20783914\n",
      "iteration  70: log likelihood of observed labels = -36390.00909449\n",
      "iteration  80: log likelihood of observed labels = -36336.32546144\n",
      "iteration  90: log likelihood of observed labels = -36283.14615871\n",
      "iteration 100: log likelihood of observed labels = -36230.46102347\n",
      "iteration 200: log likelihood of observed labels = -35728.89418769\n",
      "iteration 300: log likelihood of observed labels = -35268.51212683\n"
     ]
    }
   ],
   "source": [
    "initial_coefficients =np.zeros(194)\n",
    "step_size = 1e-7\n",
    "max_iter = 301\n",
    "print feature_matrix.shape,initial_coefficients.shape\n",
    "coefficients = logistic_regression(feature_matrix,sentiment,initial_coefficients,step_size,max_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz question**: As each iteration of gradient ascent passes, does the log likelihood increase or decrease?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# as you can see it increases "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predicting Sentiments**\n",
    "\n",
    "Recall from lecture that class predictions for a data point $\\mathbf{x}$ can be computed from the coefficients $\\mathbf{w}$ using the following formula:\n",
    "$$\n",
    "\\hat{y}_i = \n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "      +1 & \\mathbf{x}_i^T\\mathbf{w} > 0 \\\\\n",
    "      -1 & \\mathbf{x}_i^T\\mathbf{w} \\leq 0 \\\\\n",
    "\\end{array} \n",
    "\\right.\n",
    "$$\n",
    "\n",
    "Now, we will write some code to compute class predictions. We will do this in two steps:\n",
    "* **Step 1**: First compute the **scores** using **feature_matrix** and **coefficients** using a dot product.\n",
    "* **Step 2**: Using the formula above, compute the class predictions from the scores.\n",
    "\n",
    "Step 1 can be implemented as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = np.dot(feature_matrix,coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53072\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.05104571, -0.02936473,  0.02411584, ..., -0.40986295,\n",
       "        0.01411436, -0.06755923])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print len(scores)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now, complete the following code block for Step 2 to compute the class predictions using the scores obtained above:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "signs = lambda x:+1 if x>0 else -1\n",
    "class_predicted =[signs(i) for i in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n",
      "53072\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, -1, 1, 1, 1, 1, 1, 1, 1, -1]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print type(class_predicted)\n",
    "print len(class_predicted)\n",
    "class_predicted[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'collections.Counter'>\n",
      "Counter({-1: 27946, 1: 25126})\n",
      "25126 27946\n"
     ]
    }
   ],
   "source": [
    "# Quiz Question: How many reviews were predicted to have positive sentiment?\n",
    "\n",
    "from collections import Counter\n",
    "sentiment_counter=Counter(class_predicted)\n",
    "print type(sentiment_counter)\n",
    "print sentiment_counter\n",
    "positive_sentiment_counts = sentiment_counter[1]\n",
    "negative_sentiment_counts = sentiment_counter[-1]\n",
    "print positive_sentiment_counts,negative_sentiment_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring accuracy\n",
    "\n",
    "We will now measure the classification accuracy of the model. Recall from the lecture that the classification accuracy can be computed as follows:\n",
    "\n",
    "$$\n",
    "\\mbox{accuracy} = \\frac{\\mbox{# correctly classified data points}}{\\mbox{# total data points}}\n",
    "$$\n",
    "\n",
    "Complete the following code block to compute the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------\n",
      "# Reviews   correctly classified = 51619\n",
      "# Reviews incorrectly classified = 1453\n",
      "# Reviews total                  = 53072\n",
      "-----------------------------------------------------\n",
      "Accuracy = 0.97\n"
     ]
    }
   ],
   "source": [
    "num_mistakes = negative_sentiment_counts - (products['sentiment']==-1).sum()\n",
    "accuracy = float (( len(products) - num_mistakes ) )/len(products)\n",
    "print \"-----------------------------------------------------\"\n",
    "print '# Reviews   correctly classified =', len(products) - num_mistakes\n",
    "print '# Reviews incorrectly classified =', num_mistakes\n",
    "print '# Reviews total                  =', len(products)\n",
    "print \"-----------------------------------------------------\"\n",
    "print 'Accuracy = %.2f' % accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Quiz Question: What is the accuracy of the model on predictions made above? (round to 2 digits of accuracy)\n",
    "\n",
    "#Accuracy = 0.97\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which words contribute most to positive & negative sentiments?\n",
    "\n",
    "Recall that in Module 2 assignment, we were able to compute the \"**most positive words**\". These are words that correspond most strongly with positive reviews. In order to do this, we will first do the following:\n",
    "* Treat each coefficient as a tuple, i.e. (**word**, **coefficient_value**).\n",
    "* Sort all the (**word**, **coefficient_value**) tuples by **coefficient_value** in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#coefficients we have got by running our logistic regression \n",
    "coefficients = list(coefficients[1:]) # exclude intercept\n",
    "word_coefficient_tuples =[(word,coefficient) for word,coefficient in zip (important_words,coefficients) ]\n",
    "word_coefficient_tuples = sorted(word_coefficient_tuples,key=lambda x:x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, word_coefficient_tuples contains a sorted list of (word, coefficient_value) tuples. \n",
    "\n",
    "**The first 10 elements in this list correspond to the words that are most positive.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('one', 0.066546084170457695),\n",
       " ('great', 0.065890762922123244),\n",
       " ('like', 0.064794586802578394),\n",
       " ('easy', 0.045435626308421372),\n",
       " ('much', 0.044976401394906038),\n",
       " ('old', 0.03013500109210707),\n",
       " ('even', 0.029739937104968459),\n",
       " ('seat', 0.020077541034775381),\n",
       " ('perfect', 0.018408707995268992),\n",
       " ('good', 0.01770319990570169)]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print type(word_coefficient_tuples)\n",
    "word_coefficient_tuples[0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Quiz Question: Which word is not present in the top 10 \"most positive\" words?\n",
    "#see options and select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ten \"most negative\" words**\n",
    "\n",
    "Next, we repeat this exercise on the 10 most negative words. \n",
    "\n",
    "That is, we compute the 10 words that have the most negative coefficient values.\n",
    "These words are associated with negative sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('money', -0.02448210054589172),\n",
       " ('waste', -0.026592778462247283),\n",
       " ('still', -0.027742697230661327),\n",
       " ('well', -0.028711552980192581),\n",
       " ('however', -0.028978976142317068),\n",
       " ('first', -0.030051249236035804),\n",
       " ('bottles', -0.03306951529475273),\n",
       " ('day', -0.038982037286487116),\n",
       " ('bought', -0.041511033392108897),\n",
       " ('use', -0.053860148445203128)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the last 10 words from the word_coefficient_tuples \n",
    "len(word_coefficient_tuples)\n",
    "word_coefficient_tuples[len(word_coefficient_tuples)-10 : len(word_coefficient_tuples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Quiz Question: Which word is not present in the top 10 \"most negative\" words?\n",
    "#see options and select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
